# Variational Autoencoders with a Classifier Head

## What are Variational Autoencoders (VAEs)?
Variational Autoencoders (VAEs) are a type of deep learning model used for learning meaningful data representations. They encode input data into a **latent space**, which captures essential features in a compressed format. Unlike traditional autoencoders, VAEs use **probabilistic modeling** to generate diverse representations, making them useful for tasks like image generation and classification.

### How VAEs Work:
1. **Encoder:** Converts input images into a latent representation.
2. **Latent Space:** A compressed version of the data, capturing meaningful patterns.
3. **Decoder:** Attempts to reconstruct the original image from the latent representation.
4. **Classifier Head (Optional):** Uses the latent space representation to classify images into specific categories.

![VAE Structure](https://github.com/hajami0802/Variational-Autoencoders-Classifier/assets/169827483/30060413-4770-48d0-920d-bc9f438c4fcf)

---
## Goal of This Study
This research focuses on comparing two models‚Äî**PCAEClassifier** and **BetaVAEClassifier**‚Äîfor analyzing **brain MRI scans** of **Multiple Sclerosis (MS) patients**. The models aim to:
- Identify **white matter lesions (WMLs)** in MRI scans.
- Classify MRIs into two categories: **with lesions** vs. **without lesions**.
- Improve **accuracy, precision, recall, and F1-score** through different model configurations.

### Key Steps in Data Preparation:
‚úî **Data Augmentation** ‚Äì Enhancing dataset variety.
‚úî **Preprocessing** ‚Äì Cleaning and standardizing images.
‚úî **Compression & Normalization** ‚Äì Making images suitable for deep learning.

---
## Comparing PCAEClassifier and BetaVAEClassifier
### 1Ô∏è‚É£ PCAEClassifier (Deterministic Encoder)
‚úî Uses fixed convolutional layers to extract features.
‚úî Provides **consistent, deterministic outputs**.
‚úî Converges faster during training.

### 2Ô∏è‚É£ BetaVAEClassifier (Probabilistic Encoder)
‚úî Uses a **probabilistic encoding** method.
‚úî Captures **mean features** and **variability**.
‚úî Offers **richer representations** of input images.

![Encoder Types](https://github.com/hajami0802/Variational-Autoencoders-Classifier/assets/169827483/ad00b7a7-8757-4924-9fa3-053fe4a3ea4b)

---
## Model Performance Comparison
### BetaVAEClassifier Results (with different \(\beta\) values):
| Beta (\(\beta\)) | Accuracy (%) | Precision (%) | Recall (%) | F1-score (%) |
|-------------|------------|------------|-----------|-----------|
| 5           | 83.56      | 84.13      | 82.52     | 83.32     |
| 10          | 85.56      | 90.78      | 78.59     | 84.25     |
| 20          | 87.61      | 87.00      | 87.00     | 87.00     |

### PCAEClassifier Results (with different sparsity parameters \(S\)):
| Sparsity (S) | Accuracy (%) | Precision (%) | Recall (%) | F1-score (%) |
|-------------|------------|------------|-----------|-----------|
| 5           | 70.82      | 78.11      | 57.57     | 66.29     |
| 10          | 84.08      | 85.00      | 83.00     | 84.00     |
| 20          | 88.82      | 90.38      | 86.40     | 88.34     |

#### üîé Key Takeaways:
‚úî Increasing \(\beta\) in BetaVAE improves accuracy but affects recall.
‚úî Higher sparsity \(S\) in PCAEClassifier enhances accuracy and F1-score.
‚úî Model **hyperparameters significantly impact classification performance**.

---
## Architecture Breakdown
### 1Ô∏è‚É£ PCAEClassifier Architecture:
‚úî **Encoder:** Uses convolutional layers to extract features.
‚úî **Classifier:** Fully connected layers process the latent representation.
‚úî **(Optional) Decoder:** Reconstructs images for improved training stability.

![PCAEClassifier](https://github.com/hajami0802/Variational-Autoencoders-Classifier/assets/169827483/fc9dcef6-f024-4120-ad9b-f4591cddad63)

### 2Ô∏è‚É£ BetaVAEClassifier Architecture:
‚úî **Encoder:** Uses convolutional layers and encodes data as a **distribution**.
‚úî **Classifier Head:** Uses latent representation to classify MRIs.
‚úî **(Optional) Decoder:** Helps regularize training and visualize latent space.

![BetaVAEClassifier](https://github.com/hajami0802/Variational-Autoencoders-Classifier/assets/169827483/e965766a-615d-44f0-8a0c-e30dcba9f63a)

---
## Conclusion
üìå **BetaVAEClassifier** provides richer feature extraction but requires careful tuning of \(\beta\).
üìå **PCAEClassifier** is simpler but benefits from sparsity tuning.
üìå Both models show promise in **medical image analysis**, particularly in **Multiple Sclerosis (MS) classification**.
üìå Hyperparameter selection plays a crucial role in balancing **accuracy, precision, recall, and F1-score**.

---
## References
- Kingma, D. P., & Welling, M. (2019). *An introduction to variational autoencoders*. Foundations and Trends in Machine Learning.
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Muslim, A. M., et al. (2022). *Brain MRI dataset of multiple sclerosis with consensus manual lesion segmentation and patient meta information*. Data in Brief.
- Carass, A., et al. (2017). *Longitudinal multiple sclerosis lesion segmentation: resource and challenge*. NeuroImage.

‚úÖ **This study highlights how Variational Autoencoders (VAEs) with classifier heads can enhance MRI-based disease diagnosis. Future work can explore additional deep learning architectures and fine-tune hyperparameters for even better results!** üöÄ

